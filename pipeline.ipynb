{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Install and Import Libraries\n",
                "Install Kaggle API if needed and import necessary libraries."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import os\n",
                "from kaggle.api.kaggle_api_extended import KaggleApi\n",
                "\n",
                "RAW_DIR = \"data/raw\"\n",
                "PROCESSED_DIR = \"data/processed\"\n",
                "os.makedirs(RAW_DIR, exist_ok=True)\n",
                "os.makedirs(PROCESSED_DIR, exist_ok=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Download Datasets from Kaggle\n",
                "Authenticate Kaggle API and download all required datasets automatically."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "api = KaggleApi()\n",
                "api.authenticate()\n",
                "\n",
                "datasets = [\n",
                "    \"rehan497/historic-football-match-outcomes-18722022\",\n",
                "    \"patateriedata/all-international-football-results\",\n",
                "    \"martj42/international-football-results-from-1872-to-2017\",\n",
                "]\n",
                "\n",
                "for url in datasets:\n",
                "    dest = os.path.join(RAW_DIR, url.split(\"/\")[1])\n",
                "    os.makedirs(dest, exist_ok=True)\n",
                "    api.dataset_download_files(url, path=dest, unzip=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Load CSV Files\n",
                "We define a helper function to load multiple CSVs at once."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_csvs(paths):\n",
                "    return [pd.read_csv(os.path.join(RAW_DIR, p)) for p in paths]\n",
                "\n",
                "\n",
                "paths = [\n",
                "    \"all-international-football-results/all_matches.csv\",\n",
                "    \"historic-football-match-outcomes-18722022/decision.csv.csv\",\n",
                "    \"international-football-results-from-1872-to-2017/results.csv\",\n",
                "    \"historic-football-match-outcomes-18722022/FIFA Results.csv\",\n",
                "    \"international-football-results-from-1872-to-2017/goalscorers.csv\",\n",
                "    \"historic-football-match-outcomes-18722022/penality kick.csv.csv\",\n",
                "    \"international-football-results-from-1872-to-2017/shootouts.csv\",\n",
                "    \"all-international-football-results/countries_names.csv\",\n",
                "    \"international-football-results-from-1872-to-2017/former_names.csv\",\n",
                "]\n",
                "\n",
                "(\n",
                "    all_matches,\n",
                "    decision,\n",
                "    results,\n",
                "    FIFA_Results,\n",
                "    goalscorers,\n",
                "    penalty_kick,\n",
                "    shootouts,\n",
                "    countries_names,\n",
                "    former_names_csv,\n",
                ") = load_csvs(paths)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Create Country Name Mapping\n",
                "Combine the countries and former names datasets into a single mapping dictionary."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "former_names = pd.concat(\n",
                "    [\n",
                "        countries_names.iloc[:, :2].rename(\n",
                "            columns={\n",
                "                countries_names.columns[0]: \"former\",\n",
                "                countries_names.columns[1]: \"current\",\n",
                "            }\n",
                "        ),\n",
                "        former_names_csv.iloc[:, [1, 0]].rename(\n",
                "            columns={\n",
                "                former_names_csv.columns[1]: \"former\",\n",
                "                former_names_csv.columns[0]: \"current\",\n",
                "            }\n",
                "        ),\n",
                "    ],\n",
                "    ignore_index=True,\n",
                ").drop_duplicates()\n",
                "\n",
                "mapping = dict(zip(former_names[\"former\"], former_names[\"current\"]))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Apply Country Name Mapping\n",
                "Replace all occurrences of former country names in all relevant dataframes automatically."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for df in [all_matches, decision, results]:\n",
                "    df.replace(mapping, inplace=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Standardize Date Columns\n",
                "Convert date columns to a uniform `YYYY-MM-DD` format in penalty and shootout datasets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for df in [penalty_kick, shootouts]:\n",
                "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
                "    df[\"date\"] = df[\"date\"].dt.strftime(\"%Y-%m-%d\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Fix Column Typo in Penalty Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "penalty_kick.rename(columns={\"apponent_team\": \"away_team\"}, inplace=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Merge Matches"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "matches = all_matches.set_index([\"home_team\", \"away_team\", \"date\"])\n",
                "matches = matches.combine_first(decision.set_index([\"home_team\", \"away_team\", \"date\"]))\n",
                "matches = matches.combine_first(results.set_index([\"home_team\", \"away_team\", \"date\"]))\n",
                "matches = matches.reset_index()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Merge Scorers and Penalties"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scorers = pd.concat([FIFA_Results, goalscorers], ignore_index=True).drop_duplicates()\n",
                "penalties = pd.concat([penalty_kick, shootouts], ignore_index=True).drop_duplicates()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Save Processed CSVs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "matches.to_csv(f\"{PROCESSED_DIR}/matches.csv\", index=False)\n",
                "scorers.to_csv(f\"{PROCESSED_DIR}/scorers.csv\", index=False)\n",
                "penalties.to_csv(f\"{PROCESSED_DIR}/shootouts.csv\", index=False)\n",
                "former_names.to_csv(f\"{PROCESSED_DIR}/former_names.csv\", index=False)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
